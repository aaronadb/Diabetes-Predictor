{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "data=np.genfromtxt('diabetes.csv',dtype='str',delimiter=',')\n",
    "header=data[0]\n",
    "data=data[1:].astype('float64')\n",
    "x=data[:,:data.shape[1]-1]\n",
    "Y=data[:,data.shape[1]-1].reshape(data.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of data from women above the age of 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 768 rows and 9 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used for predicting the labels of data are\n",
      "['Pregnancies' 'Glucose' 'BloodPressure' 'SkinThickness' 'Insulin' 'BMI'\n",
      " 'DiabetesPedigreeFunction' 'Age']\n"
     ]
    }
   ],
   "source": [
    "print(\"The features used for predicting the labels of data are\")\n",
    "print(header[:len(header)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "MIN=x.min(axis=0)\n",
    "MAX=x.max(axis=0)\n",
    "X=(x-MIN)/(MAX-MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate accuracy\n",
    "def calculate_accuracy(predicted_Y, actual_Y):\n",
    "    c=0\n",
    "    for i in range(0,len(predicted_Y),1):\n",
    "        if(predicted_Y[i]==actual_Y[i]):\n",
    "            c=c+1\n",
    "    acc=c/len(predicted_Y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate F1 score\n",
    "def F1_score(y_pred,y):\n",
    "    tp=0\n",
    "    fn=0\n",
    "    fp=0\n",
    "    for i in range(0,len(y_pred),1):\n",
    "        if(y_pred[i]==y[i] and y_pred[i]==1):\n",
    "            tp=tp+1\n",
    "        elif(y_pred[i]==0 and y[i]==1):\n",
    "            fn=fn+1\n",
    "        elif(y_pred[i]==1 and y[i]==0):\n",
    "            fp=fp+1\n",
    "    if(tp==0):\n",
    "        return 0\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    misclassifications=(fp+fn)\n",
    "    return(2*precision*recall/(precision+recall),misclassifications,precision,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this classification problem 4 algorithms are used namely KNN, Logistic Regression, SVM and Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train, validation and test sets\n",
    "test_x=X[int(0.8*X.shape[0]):]\n",
    "test_y=Y[int(0.8*X.shape[0]):]\n",
    "train_x=X[:int(0.8*X.shape[0])]\n",
    "train_y=Y[:int(0.8*X.shape[0])]\n",
    "l=train_x.shape[0]\n",
    "val_X=train_x[int(l*0.8):]\n",
    "val_Y=train_y[int(l*0.8):]\n",
    "train_X=train_x[:int(l*0.8)]\n",
    "train_Y=train_y[:int(l*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compute the similarity between two vectors\n",
    "def compute_ln_norm_distance(vector1, vector2, n):\n",
    "    l_norm=0;\n",
    "    for i in range(0,len(vector1),1):\n",
    "        l_norm=l_norm+pow(abs(vector1[i]-vector2[i]),n)\n",
    "    l_norm=pow(l_norm,1/n)\n",
    "    return(l_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the k nearest neighbors of a given test example\n",
    "def find_k_nearest_neighbors(train_X, test_example, k, n_in_ln_norm_distance):\n",
    "    d=[]\n",
    "    for i in range(0,len(train_X),1):\n",
    "        l=compute_ln_norm_distance(train_X[i],test_example,n_in_ln_norm_distance)\n",
    "        d=d+[[l,i]]\n",
    "    d.sort()\n",
    "    p=[]\n",
    "    for i in range(0,k,1):\n",
    "        p=p+[d[i][1]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to classify the points based on the most common value of the k nearest neighbors\n",
    "def classify_points_using_knn(train_X, train_Y, test_X, n_in_ln_norm_distance, k):\n",
    "    y=[]\n",
    "    for i in range(0,len(test_X),1):\n",
    "        k_i=find_k_nearest_neighbors(train_X,test_X[i],k,n_in_ln_norm_distance)\n",
    "        K=[]\n",
    "        for j in k_i:\n",
    "            K=K+[train_Y[j]]\n",
    "        p=np.unique(K,return_counts=True)\n",
    "        p=p[0][np.argmax(p[1])]\n",
    "        y=y+[p]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 1\n",
      "F1 score = 0.5454545454545454\n",
      "For k = 2\n",
      "F1 score = 0.5416666666666666\n",
      "For k = 3\n",
      "F1 score = 0.6875\n",
      "For k = 4\n",
      "F1 score = 0.679245283018868\n",
      "For k = 5\n",
      "F1 score = 0.7076923076923077\n",
      "For k = 6\n",
      "F1 score = 0.5660377358490566\n",
      "For k = 7\n",
      "F1 score = 0.6551724137931034\n",
      "For k = 8\n",
      "F1 score = 0.6181818181818182\n",
      "For k = 9\n",
      "F1 score = 0.5573770491803278\n",
      "For k = 10\n",
      "F1 score = 0.5185185185185185\n",
      "For k = 11\n",
      "F1 score = 0.6031746031746033\n",
      "For k = 12\n",
      "F1 score = 0.5714285714285715\n",
      "For k = 13\n",
      "F1 score = 0.6\n",
      "For k = 14\n",
      "F1 score = 0.5862068965517241\n",
      "For k = 15\n",
      "F1 score = 0.6101694915254238\n",
      "For k = 16\n",
      "F1 score = 0.6206896551724138\n",
      "For k = 17\n",
      "F1 score = 0.6229508196721312\n",
      "For k = 18\n",
      "F1 score = 0.6071428571428571\n",
      "For k = 19\n",
      "F1 score = 0.6333333333333334\n",
      "For k = 20\n",
      "F1 score = 0.6206896551724138\n",
      "For k = 21\n",
      "F1 score = 0.6229508196721312\n",
      "For k = 22\n",
      "F1 score = 0.631578947368421\n",
      "For k = 23\n",
      "F1 score = 0.6333333333333334\n",
      "For k = 24\n",
      "F1 score = 0.6071428571428571\n",
      "For k = 25\n",
      "F1 score = 0.6440677966101696\n",
      "For k = 26\n",
      "F1 score = 0.6206896551724138\n",
      "For k = 27\n",
      "F1 score = 0.6206896551724138\n",
      "For k = 28\n",
      "F1 score = 0.6181818181818182\n",
      "For k = 29\n",
      "F1 score = 0.6071428571428571\n"
     ]
    }
   ],
   "source": [
    "#to find the best value of k using the validation set\n",
    "F1=0\n",
    "k=0\n",
    "n_in_ln_norm_distance=2\n",
    "for i in range(1,30,1):\n",
    "    print(\"For k =\",i)\n",
    "    y_pred=classify_points_using_knn(train_X,train_Y,val_X,n_in_ln_norm_distance,i)\n",
    "    f1,mis,pre,rec=F1_score(y_pred,val_Y)\n",
    "    print(\"F1 score =\",f1)\n",
    "    if(f1>F1):\n",
    "        F1=f1\n",
    "        k=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimum value of k is\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(\"The optimum value of k is\")\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the labels of the test set\n",
    "predicted_test_y=classify_points_using_knn(train_x,train_y,test_x,2,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy and F1_score\n",
    "accuracy_knn=calculate_accuracy(predicted_test_y,test_y)\n",
    "F1_knn,mis_knn,pre_knn,rec_knn=F1_score(predicted_test_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7337662337662337\n",
      "F1 score = 0.5858585858585857\n",
      "Precision = 0.6590909090909091\n",
      "Recall = 0.5272727272727272\n",
      "No. of misclassifications = 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",accuracy_knn)\n",
    "print(\"F1 score =\",F1_knn)\n",
    "print(\"Precision =\",pre_knn)\n",
    "print(\"Recall =\",rec_knn)\n",
    "print(\"No. of misclassifications =\",mis_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=x[int(0.8*X.shape[0]):]\n",
    "test_y=Y[int(0.8*X.shape[0]):]\n",
    "train_x=x[:int(0.8*X.shape[0])]\n",
    "train_y=Y[:int(0.8*X.shape[0])]\n",
    "l=train_x.shape[0]\n",
    "val_X=train_x[int(l*0.8):]\n",
    "val_Y=train_y[int(l*0.8):]\n",
    "train_X=train_x[:int(l*0.8)]\n",
    "train_Y=train_y[:int(l*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calucate the sigmoid of any given vector\n",
    "#the sigmoid function is given by sigmoid(x)=1/(1+e^(-x))\n",
    "def sigmoid(Z):\n",
    "    a=np.exp(-Z)\n",
    "    a=a+1\n",
    "    b=1/a\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compute the cost function\n",
    "def compute_cost(X, Y, W, b,Lambda):\n",
    "    y=sigmoid(np.dot(X,W)+b)\n",
    "    cost=(-1)*(Y*np.log(y)+(1-Y)*np.log(1-y))\n",
    "    c=np.sum(cost)+(Lambda/2)*np.dot(W.T,W)\n",
    "    c=c/X.shape[0]\n",
    "    return c[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compute the gradient of the cost function\n",
    "def compute_gradient_of_cost_function(X, Y, W, b,Lambda):\n",
    "    a=sigmoid(np.dot(X,W)+b)\n",
    "    z=a-Y\n",
    "    db=np.sum(z)\n",
    "    db=db/X.shape[0]\n",
    "    dW=np.dot(X.T,z)\n",
    "    dW=dW+Lambda*W\n",
    "    dW=dW/X.shape[0]\n",
    "    return(dW,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict the labels\n",
    "def predict_labels(X, W, b):\n",
    "    a=sigmoid(np.dot(X,W)+b)\n",
    "    a=np.where(a>=0.5,1,0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent:used to find the optimum value of the parameters W and b\n",
    "def gradient_descent(X,Y,alpha,num_iters,Lambda):\n",
    "    W=np.zeros((X.shape[1],1))\n",
    "    b=0\n",
    "    for i in range(0,num_iters,1):\n",
    "        dW,db=compute_gradient_of_cost_function(X,Y,W,b,Lambda)\n",
    "        W=W-alpha*dW\n",
    "        b=b-alpha*db\n",
    "    return(W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 0\n",
      "F1 score = 0.45614035087719296\n",
      "For lambda = 1\n",
      "F1 score = 0.45614035087719296\n",
      "For lambda = 3\n",
      "F1 score = 0.45614035087719296\n",
      "For lambda = 10\n",
      "F1 score = 0.45614035087719296\n",
      "For lambda = 30\n",
      "F1 score = 0.4642857142857143\n",
      "For lambda = 100\n",
      "F1 score = 0.43636363636363634\n",
      "For lambda = 1000\n",
      "F1 score = 0.4528301886792453\n"
     ]
    }
   ],
   "source": [
    "# to find the optimum value of the regularization parameter lambda\n",
    "l=[0,1,3,10,30,100,1000]\n",
    "F1=0\n",
    "for i in l:\n",
    "    print(\"For lambda =\",i)\n",
    "    W,b=gradient_descent(train_X,train_Y,0.0002,100000,i)\n",
    "    pred=predict_labels(val_X,W,b)\n",
    "    f1,mis,pre,rec=F1_score(pred,val_Y)\n",
    "    print(\"F1 score =\",f1)\n",
    "    if(f1>F1):\n",
    "        F1=f1\n",
    "        Lambda=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimum value of Lambda is\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(\"The optimum value of Lambda is\")\n",
    "print(Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the algorithm on the train + validation set using the optimum value of lambda\n",
    "W,b=gradient_descent(train_x,train_y,0.0002,500000,Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the labels of the test set\n",
    "pred_y=predict_labels(test_x,W,b)\n",
    "#calculating accuracy and F1 score\n",
    "accuracy_lr=calculate_accuracy(pred_y,test_y)\n",
    "F1_lr,mis_lr,pre_lr,rec_lr=F1_score(pred_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7402597402597403\n",
      "F1 score = 0.5555555555555556\n",
      "Precision = 0.7142857142857143\n",
      "Recall = 0.45454545454545453\n",
      "No. of misclassifications = 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",accuracy_lr)\n",
    "print(\"F1 score =\",F1_lr)\n",
    "print(\"Precision =\",pre_lr)\n",
    "print(\"Recall =\",rec_lr)\n",
    "print(\"No. of misclassifications =\",mis_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=X[int(0.8*X.shape[0]):]\n",
    "test_y=Y[int(0.8*X.shape[0]):]\n",
    "train_x=X[:int(0.8*X.shape[0])]\n",
    "train_y=Y[:int(0.8*X.shape[0])]\n",
    "l=train_x.shape[0]\n",
    "val_X=train_x[int(l*0.8):]\n",
    "val_Y=train_y[int(l*0.8):]\n",
    "train_X=train_x[:int(l*0.8)]\n",
    "train_Y=train_y[:int(l*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the package necessary for SVM\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 1\n",
      "F1 score = 0.7333333333333333\n",
      "For C = 2\n",
      "F1 score = 0.721311475409836\n",
      "For C = 3\n",
      "F1 score = 0.721311475409836\n",
      "For C = 4\n",
      "F1 score = 0.7301587301587302\n",
      "For C = 5\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 6\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 7\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 8\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 9\n",
      "F1 score = 0.71875\n",
      "For C = 10\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 11\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 12\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 13\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 14\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 15\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 16\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 17\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 18\n",
      "F1 score = 0.7096774193548386\n",
      "For C = 19\n",
      "F1 score = 0.7096774193548386\n",
      "For C = 20\n",
      "F1 score = 0.7096774193548386\n",
      "For C = 21\n",
      "F1 score = 0.7096774193548386\n",
      "For C = 22\n",
      "F1 score = 0.7096774193548386\n",
      "For C = 23\n",
      "F1 score = 0.7096774193548386\n",
      "For C = 24\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 25\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 26\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 27\n",
      "F1 score = 0.6984126984126984\n",
      "For C = 28\n",
      "F1 score = 0.6875\n",
      "For C = 29\n",
      "F1 score = 0.6875\n",
      "For C = 30\n",
      "F1 score = 0.6875\n",
      "For C = 31\n",
      "F1 score = 0.6875\n",
      "For C = 32\n",
      "F1 score = 0.6875\n",
      "For C = 33\n",
      "F1 score = 0.6875\n",
      "For C = 34\n",
      "F1 score = 0.6875\n",
      "For C = 35\n",
      "F1 score = 0.6875\n",
      "For C = 36\n",
      "F1 score = 0.6875\n",
      "For C = 37\n",
      "F1 score = 0.6875\n",
      "For C = 38\n",
      "F1 score = 0.6875\n",
      "For C = 39\n",
      "F1 score = 0.6875\n",
      "For C = 40\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 41\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 42\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 43\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 44\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 45\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 46\n",
      "F1 score = 0.7076923076923077\n",
      "For C = 47\n",
      "F1 score = 0.6875\n",
      "For C = 48\n",
      "F1 score = 0.6875\n",
      "For C = 49\n",
      "F1 score = 0.6875\n",
      "For C = 50\n",
      "F1 score = 0.6875\n",
      "For C = 51\n",
      "F1 score = 0.676923076923077\n",
      "For C = 52\n",
      "F1 score = 0.676923076923077\n",
      "For C = 53\n",
      "F1 score = 0.676923076923077\n",
      "For C = 54\n",
      "F1 score = 0.676923076923077\n",
      "For C = 55\n",
      "F1 score = 0.676923076923077\n",
      "For C = 56\n",
      "F1 score = 0.676923076923077\n",
      "For C = 57\n",
      "F1 score = 0.676923076923077\n",
      "For C = 58\n",
      "F1 score = 0.676923076923077\n",
      "For C = 59\n",
      "F1 score = 0.676923076923077\n",
      "For C = 60\n",
      "F1 score = 0.676923076923077\n",
      "For C = 61\n",
      "F1 score = 0.676923076923077\n",
      "For C = 62\n",
      "F1 score = 0.676923076923077\n",
      "For C = 63\n",
      "F1 score = 0.676923076923077\n",
      "For C = 64\n",
      "F1 score = 0.676923076923077\n",
      "For C = 65\n",
      "F1 score = 0.676923076923077\n",
      "For C = 66\n",
      "F1 score = 0.676923076923077\n",
      "For C = 67\n",
      "F1 score = 0.676923076923077\n",
      "For C = 68\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 69\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 70\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 71\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 72\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 73\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 74\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 75\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 76\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 77\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 78\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 79\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 80\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 81\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 82\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 83\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 84\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 85\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 86\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 87\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 88\n",
      "F1 score = 0.6567164179104478\n",
      "For C = 89\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 90\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 91\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 92\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 93\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 94\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 95\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 96\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 97\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 98\n",
      "F1 score = 0.6666666666666666\n",
      "For C = 99\n",
      "F1 score = 0.6567164179104478\n"
     ]
    }
   ],
   "source": [
    "#using the validation set to find the optimum value of C\n",
    "F1=0\n",
    "for i in range (1,100,1):\n",
    "    print(\"For C =\",i)\n",
    "    model=SVC(C=i,kernel='rbf',gamma='scale',decision_function_shape='ovr',break_ties=True)\n",
    "    model.fit(train_X,train_Y.reshape(train_Y.shape[0],))\n",
    "    pred_y=model.predict(val_X)\n",
    "    f1,mis,pre,rec=F1_score(pred_y,val_Y)\n",
    "    print(\"F1 score =\",f1)\n",
    "    if(f1>F1):\n",
    "        F1=f1\n",
    "        c=i\n",
    "new_model=SVC(C=c,kernel='rbf',gamma='scale',decision_function_shape='ovr',break_ties=True)\n",
    "new_model=new_model.fit(train_x,train_y.reshape(train_y.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimum value of C is\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"The optimum value of C is\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the labels of the test set\n",
    "pred_y=model.predict(test_x)\n",
    "#calculating the accuracy and F1 score\n",
    "accuracy_svm=calculate_accuracy(pred_y,test_y)\n",
    "F1_svm,mis_svm,pre_svm,rec_svm=F1_score(pred_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7857142857142857\n",
      "F1 score = 0.6857142857142857\n",
      "Precision = 0.72\n",
      "Recall = 0.6545454545454545\n",
      "No. of misclassifications = 33\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",accuracy_svm)\n",
    "print(\"F1 score =\",F1_svm)\n",
    "print(\"Precision =\",pre_svm)\n",
    "print(\"Recall =\",rec_svm)\n",
    "print(\"No. of misclassifications =\",mis_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=X[int(0.8*X.shape[0]):]\n",
    "test_y=Y[int(0.8*X.shape[0]):]\n",
    "train_x=X[:int(0.8*X.shape[0])]\n",
    "train_y=Y[:int(0.8*X.shape[0])]\n",
    "l=train_x.shape[0]\n",
    "val_X=train_x[int(l*0.8):]\n",
    "val_Y=train_y[int(l*0.8):]\n",
    "train_X=train_x[:int(l*0.8)]\n",
    "train_Y=train_y[:int(l*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of a node of the tree\n",
    "class Node:\n",
    "    def __init__(self, predicted_class, depth):\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = -1\n",
    "        self.threshold = 0\n",
    "        self.depth = depth\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict the majority class of a leaf node\n",
    "def predict_class(Y):\n",
    "    c=np.unique(Y,return_counts=True)\n",
    "    return c[0][np.argmax(c[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to split the data based on a given feature value\n",
    "def split_data_set(X, Y, feature_index, threshold):\n",
    "    left=np.where(X[:,feature_index]<threshold,True,False)\n",
    "    right=np.where(X[:,feature_index]>=threshold,True,False)\n",
    "    left_x=X[left]\n",
    "    left_y=Y[left]\n",
    "    right_x=X[right]\n",
    "    right_y=Y[right]\n",
    "    return left_x,left_y,right_x,right_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate the gini index of a particular split\n",
    "def calculate_gini_index(left_y,right_y):\n",
    "    n_l=len(left_y)\n",
    "    n_r=len(right_y)\n",
    "    gini=0\n",
    "    u_l=np.unique(left_y,return_counts=True)\n",
    "    u_r=np.unique(right_y,return_counts=True)\n",
    "    u_l=u_l[1]/n_l\n",
    "    u_r=u_r[1]/n_r\n",
    "    u_l=u_l**2\n",
    "    u_r=u_r**2\n",
    "    s_l=np.sum(u_l)\n",
    "    s_r=np.sum(u_r)\n",
    "    gini=(1-s_l)*(n_l/(n_l+n_r))+(1-s_r)*(n_r/(n_l+n_r))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get optimum split in the data\n",
    "def get_best_split(X, Y):\n",
    "    gini=1\n",
    "    for i in range(0,len(X),1):\n",
    "        for j in range(0,len(X[i]),1):\n",
    "            l_x,l_y,r_x,r_y=split_data_set(X,Y,j,X[i][j])\n",
    "            g=calculate_gini_index(l_y,r_y)\n",
    "            if((g<gini)or((g==gini)and(b_f==j)and(b_t>X[i][j]))):\n",
    "                gini=g\n",
    "                b_f=j\n",
    "                b_t=X[i][j]\n",
    "    return([b_f,b_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to construct the decision tree\n",
    "def construct_tree(X, Y, depth = 0):\n",
    "    node =Node(predict_class(Y),depth)\n",
    "    if(depth>=max_depth):\n",
    "        return node\n",
    "    if(len(np.unique(Y))==1):\n",
    "        return node\n",
    "    if(len(Y)<=min_size):\n",
    "        return node\n",
    "    b_f,b_t=get_best_split(X,Y)\n",
    "    l_x,l_y,r_x,r_y=split_data_set(X,Y,b_f,b_t)\n",
    "    node.feature_index=b_f\n",
    "    node.threshold=b_t\n",
    "    node.left=construct_tree(l_x,l_y,depth+1)\n",
    "    node.right=construct_tree(r_x,r_y,depth+1)\n",
    "    return node    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict the labels of a given data set\n",
    "def predict(root, X):\n",
    "    if(root.feature_index==-1):\n",
    "        return root.predicted_class\n",
    "    if(root.threshold>X[root.feature_index]):\n",
    "        p_c=predict(root.left,X)\n",
    "    else:\n",
    "        p_c=predict(root.right,X)\n",
    "    return p_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For maximum depth = 5 and minimum size = 5\n",
      "F1 score = 0.6285714285714286\n",
      "For maximum depth = 5 and minimum size = 10\n",
      "F1 score = 0.6285714285714286\n",
      "For maximum depth = 5 and minimum size = 20\n",
      "F1 score = 0.6849315068493151\n",
      "For maximum depth = 5 and minimum size = 30\n",
      "F1 score = 0.6849315068493151\n",
      "For maximum depth = 10 and minimum size = 5\n",
      "F1 score = 0.5797101449275361\n",
      "For maximum depth = 10 and minimum size = 10\n",
      "F1 score = 0.6000000000000001\n",
      "For maximum depth = 10 and minimum size = 20\n",
      "F1 score = 0.6478873239436619\n",
      "For maximum depth = 10 and minimum size = 30\n",
      "F1 score = 0.6176470588235293\n",
      "For maximum depth = 20 and minimum size = 5\n",
      "F1 score = 0.5479452054794521\n",
      "For maximum depth = 20 and minimum size = 10\n",
      "F1 score = 0.6000000000000001\n",
      "For maximum depth = 20 and minimum size = 20\n",
      "F1 score = 0.6301369863013698\n",
      "For maximum depth = 20 and minimum size = 30\n",
      "F1 score = 0.6176470588235293\n",
      "For maximum depth = 30 and minimum size = 5\n",
      "F1 score = 0.5479452054794521\n",
      "For maximum depth = 30 and minimum size = 10\n",
      "F1 score = 0.6000000000000001\n",
      "For maximum depth = 30 and minimum size = 20\n",
      "F1 score = 0.6301369863013698\n",
      "For maximum depth = 30 and minimum size = 30\n",
      "F1 score = 0.6176470588235293\n"
     ]
    }
   ],
   "source": [
    "#using the validation set to choose the optimum values of the hyper parameter:maximum depth and minimum size\n",
    "m_d=[5,10,20,30]\n",
    "m_s=[5,10,20,30]\n",
    "F1=0\n",
    "for i in m_d:\n",
    "    max_depth=i\n",
    "    for j in m_s:\n",
    "        print(\"For maximum depth =\",i,\"and minimum size =\",j)\n",
    "        min_size=j\n",
    "        root=construct_tree(train_X,train_Y)\n",
    "        pred_y=[]\n",
    "        for k in range(0,val_X.shape[0],1):\n",
    "            pred_y=pred_y+[predict(root,val_X[k,])]\n",
    "        f1,mis,pre,rec=F1_score(pred_y,val_Y)\n",
    "        print(\"F1 score =\",f1)\n",
    "        if(f1>F1):\n",
    "            F1=f1\n",
    "            depth=i\n",
    "            size=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth is\n",
      "5\n",
      "min_size is\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(\"max_depth is\")\n",
    "print(depth)\n",
    "print(\"min_size is\")\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the tree using the optimum values of the hyper parameters\n",
    "max_depth=depth\n",
    "min_size=size\n",
    "root=construct_tree(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the labels of the test set\n",
    "pred_y=[]\n",
    "for i in range(0,test_x.shape[0],1):\n",
    "    pred_y=pred_y+[predict(root,test_x[i,])]\n",
    "#calculating the accuracy and F1 score\n",
    "accuracy_tree=calculate_accuracy(pred_y,test_y)\n",
    "F1_tree,mis_tree,pre_tree,rec_tree=F1_score(pred_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7727272727272727\n",
      "F1 score = 0.7200000000000001\n",
      "Precision = 0.6428571428571429\n",
      "Recall = 0.8181818181818182\n",
      "No. of misclassifications = 35\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",accuracy_tree)\n",
    "print(\"F1 score =\",F1_tree)\n",
    "print(\"Precision =\",pre_tree)\n",
    "print(\"Recall =\",rec_tree)\n",
    "print(\"No. of misclassifications =\",mis_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 KNN         LR        SVM      DTree\n",
      "Accuracy                    0.733766   0.740260   0.785714   0.772727\n",
      "Precision                   0.659091   0.714286   0.720000   0.642857\n",
      "Recall                      0.527273   0.454545   0.654545   0.818182\n",
      "F1 Score                    0.585859   0.555556   0.685714   0.720000\n",
      "No. of Misclassifications  41.000000  40.000000  33.000000  35.000000\n"
     ]
    }
   ],
   "source": [
    "matrix={'KNN':{'Accuracy':accuracy_knn,'Precision':pre_knn,'Recall':rec_knn,'F1 Score':F1_knn,'No. of Misclassifications':mis_knn},'LR':{'Accuracy':accuracy_lr,'Precision':pre_lr,'Recall':rec_lr,'F1 Score':F1_lr,'No. of Misclassifications':mis_lr},'SVM':{'Accuracy':accuracy_svm,'Precision':pre_svm,'Recall':rec_svm,'F1 Score':F1_svm,'No. of Misclassifications':mis_svm},'DTree':{'Accuracy':accuracy_tree,'Precision':pre_tree,'Recall':rec_tree,'F1 Score':F1_tree,'No. of Misclassifications':mis_tree}}\n",
    "matrix=pd.DataFrame(matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we can see that the Decision Tree has the highest F1 score while the SVM has the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table we also see that the Decision Tree has the highest recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means that it has the fewest false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas the SVM has th highest precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means that it has the fewest false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the algorithm here is used for diabetes classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the Decision Tree is preferred as it has the highest recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
